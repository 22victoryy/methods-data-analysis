{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STA302 Project 2 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Simualate the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "## Simulation for correlated predictors ## \n",
    "set.seed(1003998757)\n",
    "\n",
    "nsample <- 10\n",
    "nsim <- 100\n",
    "\n",
    "sig2 <- rchisq(1, df = 1) ## The true error variance\n",
    "\n",
    "bet <- c(rnorm(3, 0, 1), 0) ## 4 values of beta that is beta0, beta1, beta2, beta3 = 0\n",
    "\n",
    "muvec <- rnorm(3, 0, 1)\n",
    "sigmat <- diag(rchisq(3, df = 4))\n",
    "X <- mvrnorm(nsample, mu = muvec, Sigma = sigmat)\n",
    "Xmat <- cbind(1, X)\n",
    "\n",
    "## Simulate the response ##\n",
    "bets <- matrix(NA, ncol = length(bet), nrow = nsim)\n",
    "\n",
    "\n",
    "for(i in 1:nsim){\n",
    "    Y <- Xmat%*%bet + rnorm(nsample, 0, sig2)\n",
    "    model1 <- lm(Y ~ X)\n",
    "    bets[i,] <- coef(model1)\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.First assume that the correlation between the three predictors are zero, i.e., the off diagonals of sigmat are zero. Set the number of simulations nsim = 100. Generate Y for each simulation. Then run simple linear regression for each of the three variables seperately. Obtain the regression parameter estimates and their variances from the coefficients tables obtained from the lm function. Comment on whether the estimates are unbiased. Also, comment on their variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Now fit a multiple linear regression and obtain the regression parameter estimates along with their variances from each simulation. Again check the unbiasedness and the variances. Compare the results with step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now assume X1 and X2 are correlated. You can select a value for correlation (e.g., r12 = 0.2). Then add the following covariance terms in the sigmat matrix,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.336824851739876"
      ],
      "text/latex": [
       "0.336824851739876"
      ],
      "text/markdown": [
       "0.336824851739876"
      ],
      "text/plain": [
       "[1] 0.3368249"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## The correlation ##\n",
    "r12 <- 0.2\n",
    "sigmat[1,2] <- sigmat[2,1] <- r12*sqrt(sigmat[1,1])*sqrt(sigmat[2,2])\n",
    "\n",
    "## Simulation for Categorical Variables with Interaction ##\n",
    "set.seed(1002656486)\n",
    "X <- mvrnorm(nsample, mu = muvec, Sigma = sigmat)\n",
    "cor(X[,1], X[,2])\n",
    "Xmat <- cbind(1, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again run simple linear regressions on each of the predictors and also a multiple linear re- gression. Compare the results with step 1 and 2 and comment on the differences/similarities between the results. Start increasing the value of the correlation coefficient r12, (e.g., 0.5, 0.7, 0.8 etc.) and again perform step 1 and 2. How do the estimates and standard error of β1 and β2 change for simple and multiple linear regressions as the correlation changes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Now assume X1 and X2 are uncorrelated, i.e., r12 = 0 and sigmat[1,2] = sigmat[2,1] = 0. Instead X1 and X3 are correlated. Select a value for r13 arbitrarily (e.g., r13 = 0.5). Now change the values of sigma[1,3] and sigmat[3,1] using similar codes as You can select a value for correlation (e.g., r13 = 0.5). Recall, that the true β3 = 0. Againperform step 1 and 2. Compare the results with the results obtained from step 3 and comment on the differences/similarities. Start increasing the value of the correlation coefficient r13, (e.g., 0.5, 0.7, 0.8, 0.9, 0.95 etc.). How do the estimates and standard error of β1 and β2 change for simple and multiple linear regression as the correlation changes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Please set your student ID as seed. Generate 500 random values from X1 ∼ Uniform[0, 1], X2 ∼ Uniform[0, 1], X3 ∼ Uniform[0, 1], X4 ∼ Uniform[0, 1], X5 ∼ Uniform[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate, Y = 4[sin(πx1x2) + 8(x3 − 0.5)3 + 1.5x4 − x5 − 0.77] + ε. Here, π = 3.14..... and ε ∼ N(0, 1). You can use the following codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This following function provides a data set with p+1 columns #\n",
    "gendata <- function(n, p){\n",
    "    Xmat <- matrix(runif(n*p, 0, 1), nrow = n, ncol = p)\n",
    "    Y <- 4*( (sin(pi*Xmat[,1]*Xmat[,2])) + 8*(Xmat[,3] - 0.5)^3 + 1.5*Xmat[,4] - Xmat[,5] - 0.77) + rnorm(n, 0, 1)\n",
    "    dat <- cbind(Xmat, Y)\n",
    "    return(dat)\n",
    "}\n",
    "\n",
    "set.seed(1003998757)\n",
    "dat <- gendata(500, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In real life data we don’t know the true relationship between the response and predictors. The only thing we have is the dataset dat. Perform a multiple regression analysis on the response Y with the 5 predictors in the dataset. Check all the diagnostics (leverages, influential observations, standardized residuals etc.). Comment on your findings.The simulation here needs to be done only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Simulate further 200 observations using gendata using the following code,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.new <- gendata(200, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Using the results obtained from step 1 calculate the mean prediction error of the new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Apply appropriate transformations (whatever transformation you think will help). Perform step 1 and 2 again. Explain your findings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
